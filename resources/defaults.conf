[default]
# location of activities (TCX) files
activities_dir = ${data_dir}/activities
# where to copy to-be-imported files
import_dir = ${data_dir}/to-import



## activity

# garmin to application defined canonical activity types (used for DB storage)
[activity_type]
bmx = c
cycling = c
cyclocross = c
downhill_biking = c
gravel_cycling = c
indoor_cycling = i
indoor_running = r
lap_swimming = l
mountain_biking = c
multi_sport = m
obstacle_run = r
open_water_swimming = o
recumbent_cycling = c
road_biking = c
running = r
street_running = r
strength_training = s
track_cycling = c
track_running = r
trail_running = r
treadmill_running = t
virtual_ride = c
virtual_run = r

# canonical activity type to name to nice human readable
[activity_name]
c = cycling
r = running
i = indoor cycling
t = treadmill running
l = lap swimming
o = open water swimming
s = strength training
m = multi-sport



## downloading activities

# download TCX config
[download]
# minimize size in bytes of a TCX file that would otherwise raise an exception
min_size = 1024
# how large the batch for each invocation
activity_chunk_size = 50
# default upper limit on number of activities to download (higher number for
# intial download of all activities, which is assumed to be less than 100
# thousand with this configuration, which if you completed 3 works every day
# would be 91 years :)
activity_num = 100000



## backup
[backup]
# the directory to make SQLite file backups of the database
db_backup_dir = ${default:data_dir}/db/backup
# number of days between backups of the activities SQLite database
days = 14



## DB

# persister (sqlite SQL)
[sql]
init_sql = list: create_act, create_backs
create_act = create table activity (id varchar, start_time timestamp, atype varchar(1), download_time timestamp, import_time timestamp, raw text)
insert_act = insert into activity (id, start_time, atype, raw) values (?, ?, ?, ?)
exists_act = select 1 from activity where id = ?
missing_downloads = select raw from activity where download_time is null limit ?
update_downloaded = update activity set download_time = ? where id = ?
missing_imported = select raw from activity where download_time is not null and import_time is null limit ?
update_imported = update activity set import_time = ? where id = ?
create_backs = create table backups (backup_time timestamp, file varchar)
insert_back = insert into backups (backup_time, file) values (?, ?)
last_back = select backup_time, file from backups order by backup_time desc limit 1
activity_by_date = select raw from activity where date(start_time) = ?



## google
[google_sheets]
# google sheets API key
# https://developers.google.com/api-client-library/python/start/get_started
cred_file = ${default:data_dir}/google.json
# cache token data on the file system (created on first run)
token_file = ${default:data_dir}/token.json
# long ID found in the URL when browsing to the spreadsheet in google docs
sheet_id = No_Sheet ID_Given
# number of rows we can for empty entries
maxdays = 365
# first row in the sheet
row_offset = 3
# date column (needs to be in mm/dd/yyyy format)
# cell range where the data is in the format <sheet name (bottom left tab)>!<column letter><row number>
date_cell_range = Training!B${row_offset}:B${maxdays}
# completed data cell range (same as date_cell_range)
completed_cell_range_format = Training!G{}:J{}

# canonical activity type to name to nice human readable; this is used to
# populate swim/bike/run columns in the spreadsheet
[activity_sheet]
c = bike
r = run
i = bike
t = run
l = swim
o = swim
s = strength
m = <skip>

## Google Sheets integration
[google_service_params]
# google sheets API URL
scope = https://www.googleapis.com/auth/spreadsheets
# name of REST service
api = sheets
# API version
version = v4
